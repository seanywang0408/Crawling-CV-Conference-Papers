{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver  \n",
    "from selenium.webdriver.common.by import By\n",
    "import time  \n",
    "import urllib  \n",
    "from slugify import slugify\n",
    "import requests\n",
    "import random\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conference_url = \"https://openaccess.thecvf.com/CVPR2023?day=all\" # the conference url to download papers from\n",
    "Edgedriver_path = r'C:\\Users\\hxy\\Downloads\\msedgedriver.exe'.replace('\\\\','/') # the chromedriver.exe path\n",
    "root = r'D:\\OneDrive\\academics\\papers\\conferences\\CVPR-2023-ALL'.replace('\\\\','/') # file path to save the downloaded papers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/OneDrive/academics/papers/conferences/CVPR-2023-ALL\n",
      "C:/Users/hxy/Downloads/msedgedriver.exe\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(root, exist_ok=True)\n",
    "print(root)\n",
    "print(Edgedriver_path)\n",
    "driver = webdriver.Edge()  \n",
    "driver.get(conference_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pdfurllist =  []\n",
    "pdfnamelist = []\n",
    "\n",
    "# title_element_list = driver.find_elements_by_class_name('ptitle')\n",
    "# url_element_list = driver.find_elements_by_partial_link_text('pdf')\n",
    "title_element_list = driver.find_elements(by=By.CLASS_NAME, value='ptitle')\n",
    "url_element_list = driver.find_elements(by=By.PARTIAL_LINK_TEXT, value='pdf')\n",
    "for i, element in enumerate(url_element_list): \n",
    "\n",
    "    pdfnamelist.append(title_element_list[i].text)\n",
    "    pdfurllist.append(url_element_list[i].get_attribute('href'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 pdf urls:\n",
      "\n",
      "https://openaccess.thecvf.com/content/CVPR2023/papers/Ci_GFPose_Learning_3D_Human_Pose_Prior_With_Gradient_Fields_CVPR_2023_paper.pdf\n",
      "https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_CXTrack_Improving_3D_Point_Cloud_Tracking_With_Contextual_Information_CVPR_2023_paper.pdf\n",
      "https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Deep_Frequency_Filtering_for_Domain_Generalization_CVPR_2023_paper.pdf\n",
      "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Frame_Flexible_Network_CVPR_2023_paper.pdf\n",
      "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Unsupervised_Cumulative_Domain_Adaptation_for_Foggy_Scene_Optical_Flow_CVPR_2023_paper.pdf\n",
      "\n",
      "The last 5 pdf urls:\n",
      "\n",
      "https://openaccess.thecvf.com/content/CVPR2023/papers/Ma_Curvature-Balanced_Feature_Manifold_Learning_for_Long-Tailed_Classification_CVPR_2023_paper.pdf\n",
      "https://openaccess.thecvf.com/content/CVPR2023/papers/Ahn_Interactive_Cartoonization_With_Controllable_Perceptual_Factors_CVPR_2023_paper.pdf\n",
      "https://openaccess.thecvf.com/content/CVPR2023/papers/Gunawan_Modernizing_Old_Photos_Using_Multiple_References_via_Photorealistic_Style_Transfer_CVPR_2023_paper.pdf\n",
      "https://openaccess.thecvf.com/content/CVPR2023/papers/Lamb_Fantastic_Breaks_A_Dataset_of_Paired_3D_Scans_of_Real-World_CVPR_2023_paper.pdf\n",
      "https://openaccess.thecvf.com/content/CVPR2023/papers/Yan_CIMI4D_A_Large_Multimodal_Climbing_Motion_Dataset_Under_Human-Scene_Interactions_CVPR_2023_paper.pdf\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# check the retrieved urls\n",
    "print('The first 5 pdf urls:\\n')\n",
    "for i in range(5):\n",
    "    print(pdfurllist[i])\n",
    "print('\\nThe last 5 pdf urls:\\n')\n",
    "for i in range(5):\n",
    "    print(pdfurllist[-(i+1)])\n",
    "print('=======================================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 pdf titles:\n",
      "\n",
      "GFPose: Learning 3D Human Pose Prior With Gradient Fields\n",
      "CXTrack: Improving 3D Point Cloud Tracking With Contextual Information\n",
      "Deep Frequency Filtering for Domain Generalization\n",
      "Frame Flexible Network\n",
      "Unsupervised Cumulative Domain Adaptation for Foggy Scene Optical Flow\n",
      "\n",
      "The last 5 pdf titles:\n",
      "\n",
      "Curvature-Balanced Feature Manifold Learning for Long-Tailed Classification\n",
      "Interactive Cartoonization With Controllable Perceptual Factors\n",
      "Modernizing Old Photos Using Multiple References via Photorealistic Style Transfer\n",
      "Fantastic Breaks: A Dataset of Paired 3D Scans of Real-World Broken Objects and Their Complete Counterparts\n",
      "CIMI4D: A Large Multimodal Climbing Motion Dataset Under Human-Scene Interactions\n"
     ]
    }
   ],
   "source": [
    "# check the retrieved paper titles\n",
    "print('The first 5 pdf titles:\\n')\n",
    "for i in range(5):\n",
    "    print(pdfnamelist[i])\n",
    "print('\\nThe last 5 pdf titles:\\n')\n",
    "for i in range(5):\n",
    "    print(pdfnamelist[-(i+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of papers is  2359\n"
     ]
    }
   ],
   "source": [
    "print('The number of papers is ', len(pdfnamelist))\n",
    "assert len(pdfnamelist)==len(pdfurllist), 'The number of titles and the number of urls are not matched. \\\n",
    "                                            You might solve the problem by checking the HTML code in the \\\n",
    "                                            website yourself or you could ask the author by raising an issue.'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start downloading\n",
      "0 \t GFPose: Learning 3D Human Pose Prior With Gradient Fields \t https://openaccess.thecvf.com/content/CVPR2023/papers/Ci_GFPose_Learning_3D_Human_Pose_Prior_With_Gradient_Fields_CVPR_2023_paper.pdf\n",
      "1 \t CXTrack: Improving 3D Point Cloud Tracking With Contextual Information \t https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_CXTrack_Improving_3D_Point_Cloud_Tracking_With_Contextual_Information_CVPR_2023_paper.pdf\n",
      "2 \t Deep Frequency Filtering for Domain Generalization \t https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Deep_Frequency_Filtering_for_Domain_Generalization_CVPR_2023_paper.pdf\n",
      "3 \t Frame Flexible Network \t https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Frame_Flexible_Network_CVPR_2023_paper.pdf\n",
      "4 \t Unsupervised Cumulative Domain Adaptation for Foggy Scene Optical Flow \t https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Unsupervised_Cumulative_Domain_Adaptation_for_Foggy_Scene_Optical_Flow_CVPR_2023_paper.pdf\n",
      "5 \t NoisyTwins: Class-Consistent and Diverse Image Generation Through StyleGANs \t https://openaccess.thecvf.com/content/CVPR2023/papers/Rangwani_NoisyTwins_Class-Consistent_and_Diverse_Image_Generation_Through_StyleGANs_CVPR_2023_paper.pdf\n",
      "6 \t DisCoScene: Spatially Disentangled Generative Radiance Fields for Controllable 3D-Aware Scene Synthesis \t https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_DisCoScene_Spatially_Disentangled_Generative_Radiance_Fields_for_Controllable_3D-Aware_Scene_CVPR_2023_paper.pdf\n",
      "7 \t Revisiting Self-Similarity: Structural Embedding for Image Retrieval \t https://openaccess.thecvf.com/content/CVPR2023/papers/Lee_Revisiting_Self-Similarity_Structural_Embedding_for_Image_Retrieval_CVPR_2023_paper.pdf\n",
      "8 \t Minimizing the Accumulated Trajectory Error To Improve Dataset Distillation \t https://openaccess.thecvf.com/content/CVPR2023/papers/Du_Minimizing_the_Accumulated_Trajectory_Error_To_Improve_Dataset_Distillation_CVPR_2023_paper.pdf\n",
      "9 \t Decoupling-and-Aggregating for Image Exposure Correction \t https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Decoupling-and-Aggregating_for_Image_Exposure_Correction_CVPR_2023_paper.pdf\n",
      "10 \t Implicit Occupancy Flow Fields for Perception and Prediction in Self-Driving \t https://openaccess.thecvf.com/content/CVPR2023/papers/Agro_Implicit_Occupancy_Flow_Fields_for_Perception_and_Prediction_in_Self-Driving_CVPR_2023_paper.pdf\n",
      "11 \t CCuantuMM: Cycle-Consistent Quantum-Hybrid Matching of Multiple Shapes \t https://openaccess.thecvf.com/content/CVPR2023/papers/Bhatia_CCuantuMM_Cycle-Consistent_Quantum-Hybrid_Matching_of_Multiple_Shapes_CVPR_2023_paper.pdf\n",
      "12 \t TrojViT: Trojan Insertion in Vision Transformers \t https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_TrojViT_Trojan_Insertion_in_Vision_Transformers_CVPR_2023_paper.pdf\n",
      "13 \t MarS3D: A Plug-and-Play Motion-Aware Model for Semantic Segmentation on Multi-Scan 3D Point Clouds \t https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_MarS3D_A_Plug-and-Play_Motion-Aware_Model_for_Semantic_Segmentation_on_Multi-Scan_CVPR_2023_paper.pdf\n",
      "14 \t An Image Quality Assessment Dataset for Portraits \t https://openaccess.thecvf.com/content/CVPR2023/papers/Chahine_An_Image_Quality_Assessment_Dataset_for_Portraits_CVPR_2023_paper.pdf\n",
      "15 \t MSeg3D: Multi-Modal 3D Semantic Segmentation for Autonomous Driving \t https://openaccess.thecvf.com/content/CVPR2023/papers/Li_MSeg3D_Multi-Modal_3D_Semantic_Segmentation_for_Autonomous_Driving_CVPR_2023_paper.pdf\n",
      "16 \t Robust Outlier Rejection for 3D Registration With Variational Bayes \t https://openaccess.thecvf.com/content/CVPR2023/papers/Jiang_Robust_Outlier_Rejection_for_3D_Registration_With_Variational_Bayes_CVPR_2023_paper.pdf\n",
      "17 \t Dynamically Instance-Guided Adaptation: A Backward-Free Approach for Test-Time Domain Adaptive Semantic Segmentation \t https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Dynamically_Instance-Guided_Adaptation_A_Backward-Free_Approach_for_Test-Time_Domain_Adaptive_CVPR_2023_paper.pdf\n",
      "18 \t Painting 3D Nature in 2D: View Synthesis of Natural Scenes From a Single Semantic Mask \t https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Painting_3D_Nature_in_2D_View_Synthesis_of_Natural_Scenes_CVPR_2023_paper.pdf\n",
      "19 \t LANIT: Language-Driven Image-to-Image Translation for Unlabeled Data \t https://openaccess.thecvf.com/content/CVPR2023/papers/Park_LANIT_Language-Driven_Image-to-Image_Translation_for_Unlabeled_Data_CVPR_2023_paper.pdf\n",
      "20 \t MoLo: Motion-Augmented Long-Short Contrastive Learning for Few-Shot Action Recognition \t https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_MoLo_Motion-Augmented_Long-Short_Contrastive_Learning_for_Few-Shot_Action_Recognition_CVPR_2023_paper.pdf\n",
      "21 \t Fast Point Cloud Generation With Straight Flows \t https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Fast_Point_Cloud_Generation_With_Straight_Flows_CVPR_2023_paper.pdf\n",
      "22 \t Text-Guided Unsupervised Latent Transformation for Multi-Attribute Image Manipulation \t https://openaccess.thecvf.com/content/CVPR2023/papers/Wei_Text-Guided_Unsupervised_Latent_Transformation_for_Multi-Attribute_Image_Manipulation_CVPR_2023_paper.pdf\n",
      "23 \t Achieving a Better Stability-Plasticity Trade-Off via Auxiliary Networks in Continual Learning \t https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_Achieving_a_Better_Stability-Plasticity_Trade-Off_via_Auxiliary_Networks_in_Continual_CVPR_2023_paper.pdf\n",
      "24 \t Power Bundle Adjustment for Large-Scale 3D Reconstruction \t https://openaccess.thecvf.com/content/CVPR2023/papers/Weber_Power_Bundle_Adjustment_for_Large-Scale_3D_Reconstruction_CVPR_2023_paper.pdf\n",
      "25 \t Picture That Sketch: Photorealistic Image Generation From Abstract Sketches \t https://openaccess.thecvf.com/content/CVPR2023/papers/Koley_Picture_That_Sketch_Photorealistic_Image_Generation_From_Abstract_Sketches_CVPR_2023_paper.pdf\n",
      "26 \t Contrastive Semi-Supervised Learning for Underwater Image Restoration via Reliable Bank \t https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Contrastive_Semi-Supervised_Learning_for_Underwater_Image_Restoration_via_Reliable_Bank_CVPR_2023_paper.pdf\n",
      "27 \t Video Event Restoration Based on Keyframes for Video Anomaly Detection \t https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Video_Event_Restoration_Based_on_Keyframes_for_Video_Anomaly_Detection_CVPR_2023_paper.pdf\n",
      "28 \t EcoTTA: Memory-Efficient Continual Test-Time Adaptation via Self-Distilled Regularization \t https://openaccess.thecvf.com/content/CVPR2023/papers/Song_EcoTTA_Memory-Efficient_Continual_Test-Time_Adaptation_via_Self-Distilled_Regularization_CVPR_2023_paper.pdf\n",
      "29 \t 3D-Aware Object Goal Navigation via Simultaneous Exploration and Identification \t https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_3D-Aware_Object_Goal_Navigation_via_Simultaneous_Exploration_and_Identification_CVPR_2023_paper.pdf\n",
      "30 \t Tri-Perspective View for Vision-Based 3D Semantic Occupancy Prediction \t https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Tri-Perspective_View_for_Vision-Based_3D_Semantic_Occupancy_Prediction_CVPR_2023_paper.pdf\n",
      "31 \t Castling-ViT: Compressing Self-Attention via Switching Towards Linear-Angular Attention at Vision Transformer Inference \t https://openaccess.thecvf.com/content/CVPR2023/papers/You_Castling-ViT_Compressing_Self-Attention_via_Switching_Towards_Linear-Angular_Attention_at_Vision_CVPR_2023_paper.pdf\n",
      "32 \t Shape, Pose, and Appearance From a Single Image via Bootstrapped Radiance Field Inversion \t https://openaccess.thecvf.com/content/CVPR2023/papers/Pavllo_Shape_Pose_and_Appearance_From_a_Single_Image_via_Bootstrapped_CVPR_2023_paper.pdf\n",
      "33 \t Unlearnable Clusters: Towards Label-Agnostic Unlearnable Examples \t https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Unlearnable_Clusters_Towards_Label-Agnostic_Unlearnable_Examples_CVPR_2023_paper.pdf\n",
      "34 \t Rethinking Federated Learning With Domain Shift: A Prototype View \t https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Rethinking_Federated_Learning_With_Domain_Shift_A_Prototype_View_CVPR_2023_paper.pdf\n"
     ]
    }
   ],
   "source": [
    "# download the papers one by one. The files are named after the titles (guaranteed to be valid file name after processed by slugify.)\n",
    "print('Start downloading')\n",
    "headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:57.0) Gecko/20100101 Firefox/57.0'}\n",
    "for i, url in enumerate(pdfurllist):\n",
    "    if url != None :      \n",
    "        pdfname = slugify(pdfnamelist[i])\n",
    "        if os.path.isfile(root+'/'+pdfname+\".pdf\"):\n",
    "            print('existed', i, '\\t', pdfnamelist[i], '\\t', pdfurllist[i])\n",
    "        else:\n",
    "            print(i, '\\t', pdfnamelist[i], '\\t', pdfurllist[i])\n",
    "            data = requests.get(pdfurllist[i], timeout=80, headers=headers).content\n",
    "            \n",
    "            with open(root+'/'+pdfname+\".pdf\", 'wb')  as f:\n",
    "                f.write(data)  \n",
    "            _ = time.sleep(random.uniform(4,5)) # for anti-anti-crawler purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c16dd9570c275ceb1b29686f39d4c11b50b517b5c1e89dcad271181d964a2f7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
